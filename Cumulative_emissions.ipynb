{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "raw_co2_data=pd.read_csv('data/owid-co2-data.csv')\n",
    "raw_co2_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>consumption_co2</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "      <th>co2_per_capita</th>\n",
       "      <th>...</th>\n",
       "      <th>ghg_per_capita</th>\n",
       "      <th>methane</th>\n",
       "      <th>methane_per_capita</th>\n",
       "      <th>nitrous_oxide</th>\n",
       "      <th>nitrous_oxide_per_capita</th>\n",
       "      <th>primary_energy_consumption</th>\n",
       "      <th>energy_per_capita</th>\n",
       "      <th>energy_per_gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7663783.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.084</td>\n",
       "      <td>475.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7752000.0</td>\n",
       "      <td>1.949480e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.092</td>\n",
       "      <td>8.696</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840000.0</td>\n",
       "      <td>2.006385e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7936000.0</td>\n",
       "      <td>2.074235e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.106</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8040000.0</td>\n",
       "      <td>2.201546e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.170</td>\n",
       "      <td>1.653</td>\n",
       "      <td>0.198</td>\n",
       "      <td>13.308</td>\n",
       "      <td>1.138</td>\n",
       "      <td>9.350</td>\n",
       "      <td>0.881</td>\n",
       "      <td>...</td>\n",
       "      <td>4.885</td>\n",
       "      <td>11.87</td>\n",
       "      <td>0.859</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13815000.0</td>\n",
       "      <td>2.503057e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.815</td>\n",
       "      <td>-11.139</td>\n",
       "      <td>-1.356</td>\n",
       "      <td>12.171</td>\n",
       "      <td>1.356</td>\n",
       "      <td>12.542</td>\n",
       "      <td>0.771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703</td>\n",
       "      <td>11.92</td>\n",
       "      <td>0.850</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14030000.0</td>\n",
       "      <td>2.515176e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>10.247</td>\n",
       "      <td>-5.251</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>11.774</td>\n",
       "      <td>1.527</td>\n",
       "      <td>14.902</td>\n",
       "      <td>0.720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14237000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>11.341</td>\n",
       "      <td>10.674</td>\n",
       "      <td>1.094</td>\n",
       "      <td>12.815</td>\n",
       "      <td>1.475</td>\n",
       "      <td>13.006</td>\n",
       "      <td>0.785</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14439000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>10.374</td>\n",
       "      <td>-8.521</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14645000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23708 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso_code      country  year     co2  co2_growth_prct  co2_growth_abs  \\\n",
       "0          AFG  Afghanistan  1949   0.015              NaN             NaN   \n",
       "1          AFG  Afghanistan  1950   0.084          475.000           0.070   \n",
       "2          AFG  Afghanistan  1951   0.092            8.696           0.007   \n",
       "3          AFG  Afghanistan  1952   0.092              NaN             NaN   \n",
       "4          AFG  Afghanistan  1953   0.106           16.000           0.015   \n",
       "...        ...          ...   ...     ...              ...             ...   \n",
       "23703      ZWE     Zimbabwe  2015  12.170            1.653           0.198   \n",
       "23704      ZWE     Zimbabwe  2016  10.815          -11.139          -1.356   \n",
       "23705      ZWE     Zimbabwe  2017  10.247           -5.251          -0.568   \n",
       "23706      ZWE     Zimbabwe  2018  11.341           10.674           1.094   \n",
       "23707      ZWE     Zimbabwe  2019  10.374           -8.521          -0.966   \n",
       "\n",
       "       consumption_co2  trade_co2  trade_co2_share  co2_per_capita  ...  \\\n",
       "0                  NaN        NaN              NaN           0.002  ...   \n",
       "1                  NaN        NaN              NaN           0.011  ...   \n",
       "2                  NaN        NaN              NaN           0.012  ...   \n",
       "3                  NaN        NaN              NaN           0.012  ...   \n",
       "4                  NaN        NaN              NaN           0.013  ...   \n",
       "...                ...        ...              ...             ...  ...   \n",
       "23703           13.308      1.138            9.350           0.881  ...   \n",
       "23704           12.171      1.356           12.542           0.771  ...   \n",
       "23705           11.774      1.527           14.902           0.720  ...   \n",
       "23706           12.815      1.475           13.006           0.785  ...   \n",
       "23707              NaN        NaN              NaN           0.708  ...   \n",
       "\n",
       "       ghg_per_capita  methane  methane_per_capita  nitrous_oxide  \\\n",
       "0                 NaN      NaN                 NaN            NaN   \n",
       "1                 NaN      NaN                 NaN            NaN   \n",
       "2                 NaN      NaN                 NaN            NaN   \n",
       "3                 NaN      NaN                 NaN            NaN   \n",
       "4                 NaN      NaN                 NaN            NaN   \n",
       "...               ...      ...                 ...            ...   \n",
       "23703           4.885    11.87               0.859           6.68   \n",
       "23704           4.703    11.92               0.850           6.55   \n",
       "23705             NaN      NaN                 NaN            NaN   \n",
       "23706             NaN      NaN                 NaN            NaN   \n",
       "23707             NaN      NaN                 NaN            NaN   \n",
       "\n",
       "       nitrous_oxide_per_capita  primary_energy_consumption  \\\n",
       "0                           NaN                         NaN   \n",
       "1                           NaN                         NaN   \n",
       "2                           NaN                         NaN   \n",
       "3                           NaN                         NaN   \n",
       "4                           NaN                         NaN   \n",
       "...                         ...                         ...   \n",
       "23703                     0.484                         NaN   \n",
       "23704                     0.467                         NaN   \n",
       "23705                       NaN                         NaN   \n",
       "23706                       NaN                         NaN   \n",
       "23707                       NaN                         NaN   \n",
       "\n",
       "       energy_per_capita  energy_per_gdp  population           gdp  \n",
       "0                    NaN             NaN   7663783.0           NaN  \n",
       "1                    NaN             NaN   7752000.0  1.949480e+10  \n",
       "2                    NaN             NaN   7840000.0  2.006385e+10  \n",
       "3                    NaN             NaN   7936000.0  2.074235e+10  \n",
       "4                    NaN             NaN   8040000.0  2.201546e+10  \n",
       "...                  ...             ...         ...           ...  \n",
       "23703                NaN             NaN  13815000.0  2.503057e+10  \n",
       "23704                NaN             NaN  14030000.0  2.515176e+10  \n",
       "23705                NaN             NaN  14237000.0           NaN  \n",
       "23706                NaN             NaN  14439000.0           NaN  \n",
       "23707                NaN             NaN  14645000.0           NaN  \n",
       "\n",
       "[23708 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we need to sort out the countries and select only a single value for each. We'll choose the latest."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "nations=pd.unique(raw_co2_data['iso_code'])\n",
    "for nat_i in nations:\n",
    "    subset=raw_co2_data[raw_co2_data['iso_code']==nat_i]\n",
    "    last_year=subset[subset['year']==subset['year'].max()]\n",
    "    if nat_i == 'AFG':\n",
    "        co2_data = last_year\n",
    "    else:\n",
    "        co2_data = co2_data.append(last_year,ignore_index=False)    \n",
    "\n",
    "\n",
    "co2_data['iso_code']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "70            AFG\n",
       "293           ALB\n",
       "397           DZA\n",
       "427           AND\n",
       "497           AGO\n",
       "           ...   \n",
       "23180         WLF\n",
       "23450    OWID_WRL\n",
       "23520         YEM\n",
       "23590         ZMB\n",
       "23707         ZWE\n",
       "Name: iso_code, Length: 214, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subset=raw_co2_data[raw_co2_data['iso_code']=='OWID_WRL']\n",
    "subset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(world.shape)\n",
    "world.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "arg_polygons=world.geometry\n",
    "arg_polygons"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exploded = world.explode()\n",
    "print(exploded.shape)\n",
    "exploded.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, then running the PyCartogram code on this exploded GeoDataFrame results is the following warning:\n",
    "> ValueError: A LinearRing must have at least 3 coordinate tuples\n",
    "The implication is that there is something duff that needs to be fixed in process of exploding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "item0=exploded.iat[0,5]\n",
    "print(item0)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Check Geometry\n",
    "def npts(geom):\n",
    "    LinRing=geom.exterior\n",
    "    coords=LinRing.coords\n",
    "    num_points=len(coords)\n",
    "    return num_points\n",
    "\n",
    "exploded['npts'] = exploded['geometry'].apply(lambda x: npts(x))\n",
    "exploded['npts'].min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a function written by JoeryJoery that will update the polygons of a GeoSeries in contiguous area form. It's available at <https://github.com/joeryjoery/PyCartogram>. I'm copying it below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cartogram(arg_polygons, arg_values, itermax=5, max_size_error=1.0001, epsilon=0.01, verbose=False):\n",
    "    \"\"\"\n",
    "    Generate an area equalizing contiguous cartogram based on the algorithm by (J. Oougenik et al., 1985).\n",
    "    \n",
    "    Note: The current function does not include interior boundaries when distorting the polygons!\n",
    "          This is due to shapely's current way of extracting boundary coordinates which make it \n",
    "          cumbersome to separate interior points from exterior points.\n",
    "    \n",
    "    :param arg_polygons: geopandas.geoseries.GeoSeries Series of shapely.geometry.Polygon or Multipolygon objects.\n",
    "    :param arg_values: (geo)pandas.Series Series of floating point values.\n",
    "    :param itermax: int (Optional, default=5) Maximum amount of iterations to perform adjusting coordinates.\n",
    "    :param max_size_error: float (Optional, default=1.0001) A maximum accuracy until terminating the procedure.\n",
    "    :param epsilon: float (Optional, default=0.01) Scalar to prevent zero division errors.\n",
    "    :param verbose: bool (Optional, default=False) Whether to print out intermediary progress. \n",
    "    \n",
    "    :returns: geopandas.geoseries.GeoSeries Copy of :arg_polygons: with the adjusted coordinates.\n",
    "    \n",
    "    :references: Dougenik, J.A., Chrisman, N.R. and Niemeyer, D.R. (1985), \n",
    "                 AN ALGORITHM TO CONSTRUCT CONTINUOUS AREA CARTOGRAMS*. \n",
    "                 The Professional Geographer, 37: 75-81. doi:10.1111/j.0033-0124.1985.00075.x \n",
    "    \n",
    "    :see: Implementation of the same algorithm in R (available on CRAN): https://github.com/sjewo/cartogram\n",
    "    \"\"\"    \n",
    "    \n",
    "    arg_polygons.to_crs('+proj=cea')\n",
    "    geometry = arg_polygons.copy().values\n",
    "    values = arg_values.copy().values\n",
    "    \n",
    "    total_value = values.sum()\n",
    "    mean_size_error = 100\n",
    "    \n",
    "    for iteration in range(itermax):\n",
    "        if mean_size_error < max_size_error:\n",
    "            break\n",
    "        \n",
    "        # This statement unpacks the centroid Point object to np.array and\n",
    "        # creates a n x 2 matrix of centroid [x, y] coordinates.\n",
    "        centroids = np.array(list(map(np.array, geometry.to_crs('+proj=cea').centroid.to_crs(geometry.crs))))\n",
    "        area = geometry.to_crs('+proj=cea').area\n",
    "        total_area = area.sum()\n",
    "        \n",
    "        desired = total_area * values / total_value\n",
    "        desired[desired == 0] = epsilon  # Prevent zero division.\n",
    "        radius = np.sqrt(area / np.pi)\n",
    "        mass = np.sqrt(desired / np.pi) - np.sqrt(area / np.pi)\n",
    "        \n",
    "        size_error = np.max([desired, area], axis=0) - np.min([desired, area], axis=0)\n",
    "        mean_size_error = np.mean(size_error)\n",
    "        force_reduction_factor = 1 / (1 + mean_size_error)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Mean size error at iteration {}: {}\".format(iteration+1, mean_size_error))\n",
    "        for row, item in enumerate(geometry):\n",
    "            print(row)\n",
    "            # TODO: Possibly include shapely.geometry.Polygon interior coordinates.\n",
    "            \n",
    "            # Some coordinates may appear twice, however, they mustn't be removed.\n",
    "            # These coordinates are also adjusted, but only computed once:\n",
    "            coordinates = np.matrix(item.exterior.coords)    # [[x1, y2], [x2, y2], ...]\n",
    "            idx = np.unique(coordinates, axis=0)                # Get unique rows\n",
    "            \n",
    "            for k in range(len(idx)):\n",
    "                # Get positions from coordinates for each unique idx.\n",
    "                coord_idx = np.where((coordinates[:, 0] == idx[k,0]) & (coordinates[:,1] == idx[k, 1]))[0]\n",
    "                # Only extract one using coord_idx[0] as coord_idx maps duplicate coordinates.\n",
    "                new_coordinates = coordinates[coord_idx[0],:]  \n",
    "\n",
    "                # Compute coordinate's euclidean distances to all centroids.\n",
    "                distances = np.sqrt(np.square(centroids - new_coordinates).sum(axis=1))\n",
    "                distances = np.array(distances).ravel()  # Converts matrix into flat array.\n",
    "                \n",
    "                # Compute force vectors\n",
    "                Fijs = mass * radius / distances\n",
    "                Fbij = mass * np.square(distances / radius) * (4 - 3 * distances / radius)\n",
    "                Fijs[distances <= radius] = Fbij[distances <= radius]\n",
    "                Fijs *= force_reduction_factor / distances\n",
    "                \n",
    "                # Find how much \"force\" must be applied to the coordinates by computing\n",
    "                # the dot product of the force vector and the centroid deltas.\n",
    "                new_coordinates += Fijs.dot(new_coordinates - centroids)\n",
    "\n",
    "            # Set the polygon \n",
    "            geometry[row] = Polygon(coordinates, holes = item.interiors)\n",
    "            \n",
    "    return gpd.geoseries.GeoSeries(geometry)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exploded.to_crs('+proj=cea')\n",
    "pop_cart=cartogram(exploded['geometry'], exploded['pop_est'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cartogram(arg_polygons, arg_values, itermax=5, max_size_error=1.0001, epsilon=0.01, verbose=False):\n",
    "    \"\"\"\n",
    "    Generate an area equalizing contiguous cartogram based on the algorithm by (J. Oougenik et al., 1985).\n",
    "    \n",
    "    Note: The current function does not include interior boundaries when distorting the polygons!\n",
    "          This is due to shapely's current way of extracting boundary coordinates which make it \n",
    "          cumbersome to separate interior points from exterior points.\n",
    "    \n",
    "    :param arg_polygons: geopandas.geoseries.GeoSeries Series of shapely.geometry.Polygon objects.\n",
    "    :param arg_values: (geo)pandas.Series Series of floating point values.\n",
    "    :param itermax: int (Optional, default=5) Maximum amount of iterations to perform adjusting coordinates.\n",
    "    :param max_size_error: float (Optional, default=1.0001) A maximum accuracy until terminating the procedure.\n",
    "    :param epsilon: float (Optional, default=0.01) Scalar to prevent zero division errors.\n",
    "    :param verbose: bool (Optional, default=False) Whether to print out intermediary progress. \n",
    "    \n",
    "    :returns: geopandas.geoseries.GeoSeries Copy of :arg_polygons: with the adjusted coordinates.\n",
    "    \n",
    "    :references: Dougenik, J.A., Chrisman, N.R. and Niemeyer, D.R. (1985), \n",
    "                 AN ALGORITHM TO CONSTRUCT CONTINUOUS AREA CARTOGRAMS*. \n",
    "                 The Professional Geographer, 37: 75-81. doi:10.1111/j.0033-0124.1985.00075.x \n",
    "    \n",
    "    :see: Implementation of the same algorithm in R (available on CRAN): https://github.com/sjewo/cartogram\n",
    "    \"\"\"    \n",
    "    polygons = arg_polygons.copy().values\n",
    "    values = arg_values.copy().values\n",
    "    \n",
    "    total_value = values.sum()\n",
    "    mean_size_error = 100\n",
    "    \n",
    "    for iteration in range(itermax):\n",
    "        if mean_size_error < max_size_error:\n",
    "            break\n",
    "        \n",
    "        # This statement unpacks the centroid Point object to np.array and\n",
    "        # creates a n x 2 matrix of centroid [x, y] coordinates.\n",
    "        centroids = np.array(list(map(np.array, polygons.centroid)))\n",
    "        area = polygons.area\n",
    "        total_area = area.sum()\n",
    "        \n",
    "        desired = total_area * values / total_value\n",
    "        desired[desired == 0] = epsilon  # Prevent zero division.\n",
    "        radius = np.sqrt(area / np.pi)\n",
    "        mass = np.sqrt(desired / np.pi) - np.sqrt(area / np.pi)\n",
    "        \n",
    "        size_error = np.max([desired, area], axis=0) - np.min([desired, area], axis=0)\n",
    "        mean_size_error = np.mean(size_error)\n",
    "        force_reduction_factor = 1 / (1 + mean_size_error)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Mean size error at iteration {}: {}\".format(iteration+1, mean_size_error))\n",
    "        for row, polygon in enumerate(polygons):\n",
    "            \n",
    "            # TODO: Possibly include shapely.geometry.Polygon interior coordinates.\n",
    "            \n",
    "            # Some coordinates may appear twice, however, they mustn't be removed.\n",
    "            # These coordinates are also adjusted, but only computed once:\n",
    "            coordinates = np.matrix(polygon.exterior.coords)    # [[x1, y2], [x2, y2], ...]\n",
    "            idx = np.unique(coordinates, axis=0)                # Get unique rows\n",
    "            \n",
    "            for k in range(len(idx)):\n",
    "                # Get positions from coordinates for each unique idx.\n",
    "                coord_idx = np.where((coordinates[:, 0] == idx[k,0]) & (coordinates[:,1] == idx[k, 1]))[0]\n",
    "                # Only extract one using coord_idx[0] as coord_idx maps duplicate coordinates.\n",
    "                new_coordinates = coordinates[coord_idx[0],:]  \n",
    "                \n",
    "                # Compute coordinate's euclidean distances to all centroids.\n",
    "                distances = np.sqrt(np.square(centroids - new_coordinates).sum(axis=1))\n",
    "                distances = np.array(distances).ravel()  # Converts matrix into flat array.\n",
    "                \n",
    "                # Compute force vectors\n",
    "                Fijs = mass * radius / distances\n",
    "                Fbij = mass * np.square(distances / radius) * (4 - 3 * distances / radius)\n",
    "                Fijs[distances <= radius] = Fbij[distances <= radius]\n",
    "                Fijs *= force_reduction_factor / distances\n",
    "                \n",
    "                # Find how much \"force\" must be applied to the coordinates by computing\n",
    "                # the dot product of the force vector and the centroid deltas.\n",
    "                new_coordinates += Fijs.dot(new_coordinates - centroids)\n",
    "                \n",
    "            # Set the polygon \n",
    "            polygons[row] = Polygon(coordinates, holes = polygon.interiors)\n",
    "            \n",
    "    return gpd.geoseries.GeoSeries(polygons)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exploded = world.explode()\n",
    "exploded.to_crs('+proj=cea')\n",
    "exploded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pop_cart=cartogram(exploded['geometry'], exploded['pop_est'],itermax=100,verbose=True)\n",
    "pop_cart[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pop_cart.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Check Geometry\n",
    "def compute_area(geom):\n",
    "    area = geom.area\n",
    "    return area\n",
    "\n",
    "world['area'] = world['geometry'].apply(lambda x: compute_area(x))\n",
    "world['pop_dens']=world['pop_est']/world['area']\n",
    "world['gdp_dens']=world['gdp_md_est']/world['area']\n",
    "explode_me=world.drop(['pop_est','gdp_md_est','area'],axis=1)\n",
    "exploded=explode_me.explode()\n",
    "exploded['area'] = exploded['geometry'].apply(lambda x: compute_area(x))\n",
    "exploded['pop']=exploded['pop_dens']*exploded['area']\n",
    "exploded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pop_cart=cartogram(exploded['geometry'], exploded['pop'],itermax=50,verbose=True)\n",
    "print(pop_cart[0])\n",
    "pop_cart.plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#exploded['geometry']=pop_cart\n",
    "exploded['cart']=pop_cart\n",
    "exploded.set_geometry('cart')\n",
    "#print(exploded['pop'].values)\n",
    "#print(pop_cart)\n",
    "\n",
    "df = pd.DataFrame({'pop': exploded['pop'].values})\n",
    "gdf = gpd.GeoDataFrame(df, geometry=pop_cart)\n",
    "gdf.plot('pop', label=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('jupyter_jaspy': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "3f280c1ca46db3da3cd73dea1bee03152c180ecb25fc2a8d60761b75004b3eec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}